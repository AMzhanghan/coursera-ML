{
  "name": "Coursera-ml",
  "tagline": "use numpy and tensorflow to implement these basic ML model and learning algorithm",
  "body": "# Coursera ML MOOC\r\nAndrew's class may be the common sense among ML practitioners.  \r\n\r\nI don't want to fool myself.  \r\nEven I have read some api doc of [sklearn](http://scikit-learn.org/stable/modules/classes.html) and know how to call them, I don't know the soul of machine learning. I have to get the basics right. So I implement every exercise of the [Coursera ML class](https://www.coursera.org/learn/machine-learning/home/welcome) using numpy, scipy and tensorflow.  \r\n\r\nThe reason I choose python over matlab is purely practical concern. This cs224d [Intro to TensorFlow](http://cs224d.stanford.edu/lectures/CS224d-Lecture7.pdf) ([video](https://www.youtube.com/watch?v=L8Y2_Cq2X5s&index=7&list=PLmImxx8Char9Ig0ZHSyTqGsdhb9weEGam)) presents very good explanation of why python may be the right choice to do ML.  \r\n\r\nAll these learning about theories and coding are preparation of real world application. Although the learning itself is it's own reward, I also want to create useful application that solves real world problems and create values to the community. This project is the very tiny step toward the goal. I learned so much.  \r\n\r\nThe more I learn, the more I respect all those great scientific adventures before me that paves the way I have right now. Andrew's class is very good overview of general ML. It's hands on approach  encourages new people like me keep moving, even some details are purposefully ignored. On the other hand, I found it very useful to pick up theories while doing these exercises. This book [Learning from Data](http://amlbook.com/) gives me so many aha moment about learning theories. This is my feeble foundation of ML theories.\r\n\r\nGenerally, Andrew's class shows me mostly **what** to do, and **how** to do it. The book shows me **why**. Theory and practice goes hand in hand. I couldn't express how happy I am when I read something in the book and suddenly understand the reason about what I was coding last night. Eureka!\r\n\r\n## Project structure\r\n* Each exercise has it's own folder. In each folder you will find:\r\n  1. pdf that guide you through the project\r\n  2. a series of Jupyter notebook\r\n  3. data\r\n* each notebook basically follows the logic flow of project pdf. I didn't present all codes in notebook because I personally think it's very messy. So you will only see visualization, project logic flows, simple experiments, equations and results in notebooks.\r\n* In [helper](https://github.com/icrtiou/coursera-ML/tree/master/helper) folder, it has modules of different topics. This is where you can find details of model implementation, learning algorithm, and supporting functions.\r\n\r\n## Go solo with python or go with built-in Matlab project?\r\nThe Matlab project is guiding students to finish the overall project goal, be it implementing logistic regression, or backprop NN. It includes many supporting function to help you do `visualization`,  `gradient checking`, and so on.  \r\nThe way I do it is to focus on pdf that tells you what is this project about, then figure out how to achieve those objectives using `Scipy` stack. Most of time I don't even bother looking into original `.m` files. Just need their data. \r\n\r\nWithout those supports, I have to do:\r\n\r\n1. **visualization** : `seaborn`, `matplotlib` are very handy  \r\n2. **vetorized implementation** of ML model and gradient function use `numpy`'s power to manupulate `ndarray`  \r\n3. **optimization** : figure out how to use `scipy` optimizer to fit you parameters  \r\n4. **support functions** : nobody is loading, parsing, normalize data for you now, DIY  \r\n\r\nBy doing those, I learn more, which is even better.\r\n\r\n# You can read all Jupyter notebooks here: [nbviewer](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/)\r\n\r\n> * acknowledgement: Thank you [John Wittenauer](https://github.com/jdwittenauer?tab=overview&from=2016-08-01&to=2016-08-31&utf8=%E2%9C%93)! I shamelessly steal lots of your code and idea. [here](https://github.com/jdwittenauer/ipython-notebooks)    \r\n> * if you want to run notebooks locally, you could refer to requirement.txt for libraries I've been using.  \r\n> tensorflow is a little bit tricky to install. you could find the instructions [here](https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html).  \r\n> * I'm using `python 3.5.2` for those notebooks. You will need it because I use `@` operator for matrix multiplication extensively.\r\n\r\n### [ex1-linear regression](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex1-linear%20regression/)\r\nSpecial thing I did in this project is I implement the linear regression model in [TensorFlow](https://www.tensorflow.org/). This is my first tf experience. Looking forward to learn more when I move into Deep Learning. code: [linear_regression.py](https://github.com/icrtiou/coursera-ML/blob/master/helper/linear_regression.py)\r\n### [ex2-logistic regression](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex2-logistic%20regression/)\r\n### [ex3-neural network](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex3-neural%20network/)\r\n### [ex4-NN back propagation](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex4-NN%20back%20propagation/)\r\n### [ex5-bias vs variance](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex5-bias%20vs%20variance/)\r\n### [ex6-SVM](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex6-SVM/)\r\n### [ex7-kmeans and PCA](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex7-kmeans%20and%20PCA/)\r\n### [ex8-anomaly detection and recommendation](http://nbviewer.jupyter.org/github/icrtiou/coursera-ML/tree/master/ex8-anomaly%20detection%20and%20recommendation/)\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}